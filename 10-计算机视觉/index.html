<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no" />
  <meta name="decription" content="描述" />
  <meta name="keywords" content="关键词,大聪花,bigonion,大葱花,puzzle,OpenAI,Markdwon,Music" />
  <meta name="author" content="bigonion,bigonion@bigonion.cn" />
  <meta name="robots" content="index,follow" />
  <title>U-Net：用于生物医学图像分割的卷积网络</title>
  <link rel="stylesheet" href="dist/reset.css" />
  <link rel="stylesheet" href="dist/reveal.css" />
  <link rel="stylesheet" href="dist/theme/white-contrast.css" />
  <link rel="stylesheet" href="./custom/index.css" />
  <link rel="stylesheet" href="./custom/githubMarkdownCss.css" />
  <link rel="shortcut icon" href="favicon.ico" type="image/x-icon" />
  <!-- Theme used for syntax highlighted code -->
  <link rel="stylesheet" href="plugin/highlight/monokai.css" />
</head>

<body>
  <div class="reveal">
    <div class="slides">
      <!-- 1封面标题-->
      <section data-background="black" data-transition="convex">
        <h2>U-Net：用于生物医学图像分割的卷积网络</h2>
        <hr />

        <p2 style="font-size: 4vh !important">黎文宇、蔡泓鑫、马顺欣</p2>
      </section>
      <section>
        <section>
          <h3 class="P4">什么是U-net网络</h3>
        </section>
        <section>
          <p3 class="P4">
            U-Net是一种用于图像分割的卷积神经网络模型。它由Ronneberger等人在2015年提出，主要应用于医学图像分割领域。U-Net的特点在于通过卷积和池化操作，将输入图像逐步缩小，再通过反卷积和跳跃连接操作，将图像逐步放大。这种结构允许U-Net在分割结果中保留更多的细节信息，从而提高分割质量。U-Net已经在医学影像处理中取得了很大成功，并在其他领域中也得到了广泛应用。
          </p3>
        </section>
      </section>
      <!-- 2 小标题 -->
      <section>
        <h2>问题发现与分析</h2>
      </section>
      <section data-transition="convex">
        <section data-auto-animate data-transition="convex">
          <ul>
            <li type="circle" data-id="box" class="P4">
              第一个问题，对于大部分神经网络来说，要想获得良好的性能，需要用大量的标签数据进行训练，这对生物医学图像来说，是非常困难并且难以实现的</li>
          </ul>
        </section>
        <section data-auto-animate data-transition="convex">
          <ul>
            <li type="circle" data-id="box" class="P4">
              第一个问题，对于大部分神经网络来说，要想获得良好的性能，需要用大量的标签数据进行训练，这对生物医学图像来说，是非常困难并且难以实现的</li>
            <li type="circle" data-id="box" class="P4">
              第二个问题，当时最好的网络速度慢，有大量重叠冗余的训练，并且不能平衡好定位精度和全局信息的关系
            </li>
          </ul>
        </section>
        <section data-auto-animate data-transition="convex">
          <ul>
            <li type="circle" data-id="box" class="P4">
              第一个问题，对于大部分神经网络来说，要想获得良好的性能，需要用大量的标签数据进行训练，这对生物医学图像来说，是非常困难并且难以实现的</li>
            <li type="circle" data-id="box" class="P4">
              第二个问题，当时最好的网络速度慢，有大量重叠冗余的训练，并且不能平衡好定位精度和全局信息的关系
            </li>
            <li type="circle" data-id="box" class="P4">
              第三个问题，在分割细胞图像时，如何分离互相接触的同类细胞，这也是一个挑战
            </li>
          </ul>
        </section>
      </section>
      <section data-transition="zoom">
        <h3>如何解决这些问题？</h3>
      </section>
      <section data-transition="convex">
        <section data-auto-animate data-transition="convex">
          <ul>
            <li type="circle" data-id="box" class="P4">
              第一个问题，对于大部分神经网络来说，要想获得良好的性能，需要用大量的标签数据进行训练，这对生物医学图像来说，是非常困难并且难以实现的
            </li>
          </ul>
        </section>
        <section data-auto-animate data-transition="convex">
          <ul>
            <li type="circle" data-id="box" class="P4">
              第一个问题，对于大部分神经网络来说，要想获得良好的性能，需要用大量的标签数据进行训练，这对生物医学图像来说，是非常困难并且难以实现的
            </li>
            <li type="circle" data-id="box" class="P4">
              解决方法：对量少的训练图像进行弹性变形来大幅扩展数据，从而解决训练数据集的限制。
            </li>
          </ul>
        </section>
        <!--  -->
        <section data-auto-animate data-transition="convex">
          <ul>
            <li type="circle" data-id="box" class="P4">
              第二个问题，当时最好的网络速度慢，有大量重叠冗余的训练，并且不能平衡好定位精度和全局信息的关系
            </li>
          </ul>
        </section>
        <section data-auto-animate data-transition="convex">
          <ul>
            <li type="circle" data-id="box" class="P4">
              第二个问题，当时最好的网络速度慢，有大量重叠冗余的训练，并且不能平衡好定位精度和全局信息的关系
            </li>
            <li type="circle" data-id="box" class="P4">
              解决方法：提出一个U型网络结构，也就是我们说的U-Net，通过在常规的压缩层后增加扩展层，将图像的全局信息传播到分辨率更高的层，以产生更精确的分割；并且它只需要少量的训练数据。
            </li>
          </ul>
        </section>
        <section data-auto-animate data-transition="convex">
          <ul>
            <li type="circle" data-id="box" class="P4">
              第三个问题，在分割细胞图像时，如何分离互相接触的同类细胞，这也是一个挑战
            </li>
          </ul>
        </section>
        <section data-auto-animate data-transition="convex">
          <ul>
            <li type="circle" data-id="box" class="P4">
              第三个问题，在分割细胞图像时，如何分离互相接触的同类细胞，这也是一个挑战
            </li>
            <li type="circle" data-id="box" class="P4">
              解决方法：给接触细胞的边界赋予更大的权重，使用加权损失函数来分离接触的细胞。
            </li>
          </ul>
        </section>
      </section>
      <section data-transition="fade-In convex-out">
        <section>
          <h3>数据增强</h3>
        </section>
        <section>
          <p class="P4">当只有很少的训练样本可用时，数据扩充对于教会网络所需的不变性和鲁棒性是至关重要的。(平移和旋转不变性，对变形和灰度值变化有鲁棒性)
            通过弹性形变处理训练数据从而扩展图像，在生物医学分割中特别重要也很常见，因为变形是生物组织中最常见的变化，可以有效地模拟真实的变形。因此可以有效增强网络的鲁棒性。</p>
        </section>
        <section data-auto-animate data-transition="convex" class="NOLIST">
          <ul>
            <li type="circle" data-id="box" class="P4 NOLIST">
              <img data-id="box1" src="./assets/pic/细胞.jfif" alt="">
            </li>
          </ul>
        </section>
        <section data-auto-animate data-transition="convex">
          <ul>
            <li type="circle" data-id="box1" class="P4 NOLIST">
              <p>随机变形、旋转等不规则变化来增强图像</p>
            </li>
            <li type="circle" data-id="box1" class="P4 NOLIST">
              <img id="ani_1" data-id="box1" src="./assets/pic/细胞.jfif" alt="">
            </li>
          </ul>
        </section>
      </section>
      <section data-transition="convex">
        <h3>网络结构</h3>
      </section>
      <section>
        <!-- 总图 -->
        <section data-transition="convex">
          <p class="P4">网络由左边的收缩网络和右边的扩张网络组成，这两部分网络是完全对称的，并在相同层之间通过concatenation（连接）操作进行连接。这样的网络结构像一个U，所以称他为U-net。</p>
          <img class="midPic" src="./assets/pic/网络结构.png" alt="">
        </section>
        <!-- 收缩 -->
        <section data-transition="convex">
          <p class="P4">
            收缩网络部分，是典型的卷积网络结构，每一层由两次卷积和最大池化操作组成；concatenation（连接）部分包括复制和裁剪操作
          </p>
          <img class="midPic" src="./assets/pic/收缩网络.png" alt="">
        </section>
        <!-- 卷积图 -->
        <section>
          <p class="P4">
            收缩网络由4层组成，它的每一层，对于输入图像，首先进行两次3x3的卷积，进行特征提取。然后，用ReLU激活函数增强非线性，避免了梯度爆炸和梯度消失问题。每次进行3x3的卷积，图像就会丢掉一个像素宽度的边界信息。因此，图像尺寸在不断减小。
          </p>
          <img src="./assets/pic/收缩卷积图.png" alt="">
        </section>

        <!-- 池化 -->
        <section>
          <p class="P4">两次卷积过后，进行2x2的max pool最大池化操作，来进行特征选择和信息过滤。max-pooling提取显著特征的同时降低模型的参数，从而降低模型的过拟合。操作过后的feature
            map的分辨率会减小为原来的一半，并且图像的x-y 尺寸也会减半。</p>
          <img src="./assets/pic/收缩池化.png" alt="">
        </section>
        <section data-transition="convex">
          <p class="P4">上下采样原理图</p>
          <img src="./assets/pic/上下采样原理图.png" alt="">
        </section>
        <!-- 扩张网络 -->
        <section data-transition="convex">
          <p class="P4">扩张网络与收缩网络是对称的，首先对输入图像进行2x2的上卷积操作来上采样，将feature map还原到原图大小。</p>
          <img class="midPic" src="./assets/pic/复原网络.png" alt="">
        </section>
        <section data-transition="convex">
          <p class="P4">上采样</p>
          <img src="./assets/pic/上采样.png" alt="">
        </section>

        <!-- 拼接-->
        <section data-transition="convex">
          <p class="P4">拼接收缩网络和复原网络</p>
          <img src="./assets/pic/拼接网络.png" alt=""><br>
          <p2 class="P4">最后输出的是一层前景和一层背景，前景是分割出来的物体</p2>
        </section>
        <section>
          <p class="P4">白色的是前景（细胞）黑色的是背景</p>
          <img src="./assets/pic/前景背景.png" alt="" class="midPic">
        </section>
      </section>
      <section data-background-image="./assets/pic/ai.jpg">
      </section>
      <section>
        <section>
          <p class="P2">训练网络</p>
        </section>
        <section data-markdown>
          ## softmax归一化
          `$$p_k(x)=\mathrm{exp}(\alpha_k(x))/(\sum_{k^{'}=1}^{K} \mathrm{exp}(\alpha_{k^{'}}(x)))$$`

        </section>
        <section data-markdown="">
          ## softmax例子

          `$$原输出假设为[1,2,3]$$`

          `$$p1 = \frac{e^1}{e^1+e^2+e^3}=0.09$$`
          `$$p2 = \frac{e^2}{e^1+e^2+e^3}=0.24$$`
          `$$p3 = \frac{e^3}{e^1+e^2+e^3}=0.665$$`
          `$$p1+p2+p3 =1$$`
          `$$这样e的指数增长特性可以让方差变大,并且归一化$$`
        </section>
        <section data-markdown="">
          ### 交叉熵损失函数
          `$$ E= \sum_{x\in\omega} \omega(x)\mathrm{log}(p_{l(x)}(x)) $$`
          <!-- `$$ \omega(x) = \omega_c(x) + \omega_0\cdot\mathrm{exp}(-\frac{(d_1(x)+d_2(x))^2}{2\sigma^2}) $$` -->
          `$$二分类交叉熵：L=\frac{1}{N}\sum_i L_i = \frac{1}{N}\sum_i - [y_i\cdot\log(p_i)+(1-y_i)\cdot\log(1-p_i) ]$$`
          `$$多分类交叉熵：L=\frac{1}{N}\sum_i L_i = -\frac{1}{N}\sum_i \sum_{c=1}^M y_{ic}\log(p_{ic})$$`
        </section>
        <section data-markdown="" data-auto-animate>
          ### 权重
          <!-- `$$ E= \sum_{x\in\omega} \omega(x)\mathrm{log}(p_{l(x)}(x)) $$` -->
          `$$ \omega(x) = \omega_c(x) + \omega_0\cdot\mathrm{exp}(-\frac{(d_1(x)+d_2(x))^2}{2\sigma^2}) $$`
          `$$d1：当前像素到最近细胞边界的距离，d2：当前像素到第二个最近细胞边界的距离$$`
        </section>
        <section>
          <p class="P3">通过这个公式，给接触细胞的边界赋予了更大的权重，使网络能够区分出图像中接触细胞之间的小边界。</p>
        </section>
        <!-- <section>
          <img class="smallPic" src="assets/pic/损失函数公式1.png" alt="">
          <p class="P4">wc(x)为图像的二值图，</p>
        </section> -->
      </section>
      <section>
        <p class="P2">评估网络</p>
      </section>
      <section class="GRID2 fullSectionWidth" data-transition="convex">
        <div class="FLEX COL">
          <div class="P4">
            <h3>胶质母细胞瘤细胞PhC-U373</h3>
          </div>
          <div>
            <img class="midPic NOMARGIN" src="assets/pic/评估数据1.png" alt="网络不佳" />
          </div>
        </div>
        <div class="FLEX COL">
          <div class="P4">
            <h3>宫颈癌细胞DIC-HeLa</h3>
          </div>
          <div>
            <img class="midPic NOMARGIN" src="assets/pic/数据集2.png" alt="网络不佳" />
          </div>
        </div>

      </section>
      <section>
        <p class="P4">论文里使用了两个数据集，分别是胶质母细胞瘤细胞PhC-U373、宫颈癌细胞DIC-HeLa，他们分别有35张、20张标签图像数据。

          在这样少量的数据集上训练u-net，并使用IoU交并比来计算分割精确度。下面表格中，在两个数据集上，u-net的IoU分别为0.92、0.77，相较于当时其他算法，它的准确率遥遥领先。</p>
      </section>
      <section>
        <section>
          <p class="P4">下面这些分割示例图也可以看出，对于边界不明显、含有无关内部边界、形状变化大、和背景相似度高、相互接触的细胞结构，u-net的分割结果还是比较好的。</p>
        </section>
        <section>
          <img src="assets/pic/结果分析.png" alt="" class="midPic">
        </section>
      </section>

      <!-- 总结 -->
      <section>
        <h3>总结</h3>
      </section>

      <section data-transition="convex" style="font-size: 4.5vh !important;">
        <section data-auto-animate data-transition="convex">
          <ul>
            <li type="circle" data-id="box">u-net网络结构包含收缩部分和扩展部分，分别用来提取特征信息和提高定位精度；</li>
          </ul>
        </section>
        <section data-auto-animate data-transition="convex">
          <ul>
            <li type="circle" data-id="box">u-net网络结构包含收缩部分和扩展部分，分别用来提取特征信息和提高定位精度；</li>
            <li type="circle" data-id="box">
              网络使用像素级损失函数来学习接触细胞的边界；
            </li>
          </ul>
        </section>
        <section  data-auto-animate data-transition="convex">
          <ul>
            <li type="circle" data-id="box">u-net网络结构包含收缩部分和扩展部分，分别用来提取特征信息和提高定位精度；</li>
            <li type="circle" data-id="box" >
              网络使用像素级损失函数来学习接触细胞的边界；
            </li>
            <li type="circle" data-id="box">
              使用弹性形变来扩充数据，解决生物医学图像标签数据集量少的问题，并且提高了训练速度；
            </li>
          </ul>
        </section>
        <section data-auto-animate data-transition="convex">
          <ul>
            <li type="circle" data-id="box">u-net网络结构包含收缩部分和扩展部分，分别用来提取特征信息和提高定位精度；</li>
            <li type="circle" data-id="box" >
              网络使用像素级损失函数来学习接触细胞的边界；
            </li>
            <li type="circle" data-id="box" >
              使用弹性形变来扩充数据，解决生物医学图像标签数据集量少的问题，并且提高了训练速度；
            </li>
            <li type="circle" data-id="box">
              u-net能够应用在很多不同的医学图像分割中。
            </li>
          </ul>
        </section>
      </section>

  
      <!-- 11结束 -->
      <section data-background="black">
        <h1>Thank you!</h1>
      </section>
    </div>
  </div>

  <script src="dist/reveal.js"></script>
  <script src="plugin/notes/notes.js"></script>
  <script src="plugin/markdown/markdown.js"></script>
  <script src="plugin/highlight/highlight.js"></script>
  <script src="./custom/index.js"></script>
  <script src="plugin/math/math.js"></script>
  <script src="./plugin/zoom/zoom.js"></script>
  <script>
    // More info about initialization & config:
    // - https://revealjs.com/initialization/
    // - https://revealjs.com/config/
    Reveal.configure({
      keyboard: {
        13: "next", // go to the next slide when the ENTER key is pressed
        87: "up",
        68: "next",
        65: "left",
        83: "down",
        // 32: null, // don't do anything when SPACE is pressed (i.e. disable a reveal.js default binding)
      },
    });
    Reveal.initialize({
      hash: true,
      katex: {
        version: "latest",
        delimiters: [
          { left: "$$", right: "$$", display: true },
          { left: "$", right: "$", display: false },
          { left: "\\(", right: "\\)", display: false },
          { left: "\\[", right: "\\]", display: true },
        ],
        ignoredTags: ["script", "noscript", "style", "textarea", "pre"],
      },
      // Learn about plugins: https://revealjs.com/plugins/
      plugins: [
        RevealZoom,
        RevealMath.KaTeX,
        RevealMarkdown,
        RevealHighlight,
        RevealNotes,
      ],
    });
  </script>
  <!-- <script type="module">
      import app from "./custom/module/index.js";
      app();
    </script> -->
</body>

</html>